# Neuro Radix

Проект объединяет обучение, инференс и сервис для анализа медицинских КТ-данных.  
Архитектура построена на SwinUNETR и кастомной мультизадачной голове. Даже в текущем виде (с ограничением по данным) решение демонстрирует гибкость и перспективу.

---

## Структура проекта

- **prepare_dataset.ipynb** — подготовка датасета (CT-RATE).  
- **train_swin.ipynb** — обучение SwinUNETR для сегментации.  
- **train_monster.ipynb** — обучение комплексной модели «Monster» (SwinUNETR + мультизадачная голова).  
- **inference.ipynb** — применение модели к новым данным, сохранение результатов в DICOM.  
- **microservice.py** — FastAPI микросервис для удалённого инференса.  
- **requirements.txt** — зависимости проекта.  

---

## Архитектура и подход

### Этап 1. Обучение бэкбона
- Бэкбоном служит **SwinUNETR** — гибрид Swin Transformer + U-Net.  
- Модель обучалась ~10 дней на NVIDIA A100 (80 GB VRAM) на задаче сегментации.  
- Извлекала устойчивые представления объёмов, пригодные для использования в других задачах.

### Этап 2. Извлечение эмбеддингов
- После обучения сегментации бэкбон использовался как **фич-экстрактор**.  
- Функция `custom_sliding_embeddings_encoders` прогоняла каждый 3D-скан через сеть **слайдингом** по патчам (`roi_size=(96,96,96), overlap=0.25`).  
- Для каждого патча сохранялись векторы признаков (например, размерности 1152).  
- Патчевые эмбеддинги конкатинировались и сохранялись в `.pt` файлы.  
- В датасете использовался кастомный трансформ `LoadEmbeddingD` для подгрузки этих файлов.  
- Так мы получили ~1000 эмбеддингов сканов, на которых и обучалась мультизадачная голова.

### Этап 3. Обучение головы (MultiModalMonsterUltimate)
Голова объединяет задачи классификации и генерации отчётов:  

1. **Bridge (CrossAttentionBridge):**  
   - Кросс-аттеншен между эмбеддингами сканов и скрытым пространством BART.  
   - Делит представления на два потока:  
     - `cls_repr` → классификация,  
     - `gen_repr` → генерация текста.  

2. **Классификация (MoEClassifier):**  
   - Mixture-of-Experts (по умолчанию 4 эксперта).  
   - Каждый эксперт учится на своём подмножестве признаков.  
   - Результат агрегируется в логиты по 18 классам (адаптированные CheXbert).  

3. **Генерация отчётов (BART):**  
   - Использует `gen_repr` для генерации текстового описания.  
   - Лосс: комбинация классификации и генерации (балансируется параметром `lambda_bart`).  
   - Дополнительно считается *coverage loss* для вниманий, чтобы модель не «залипала» на одинаковых токенах.  

4. **Обучение:**  
   - На вход подавались сохранённые `.pt` эмбеддинги (~1000).  
   - Одновременно решались задачи классификации и генерации.  
   - Результат: сегментационная часть сильная, но классификация и генерация недообучены из-за малого датасета.  

---

## Ограничения и планы

- **Ограничение:** маленький датасет для головы (~1000 сканов).  
- **Планы:**  
  1. Отказаться от сегментации как обязательного этапа.  
  2. Использовать **3D-ViT с позиционным кодированием** в качестве фич-экстрактора.  
  3. Добавить **контрастивный лосс** между эмбеддингами изображений и текстовыми эмбеддингами репортов.  
  4. Масштабировать обучение на полный датасет **CT-RATE**.  
  5. **Аттеншен-мапы:** реализовать сохранение карт внимания (из CrossAttentionBridge и BART) и отправлять их клиенту для визуализации вокселей, на которые модель обращала больше всего внимания.  

---

## Почему решение сильное

- **Мультизадачность:** сегментация + классификация + генерация отчётов.  
- **Фич-экстракция через патчевые эмбеддинги** из обученного бэкбона.  
- **Инженерные элементы:** CrossAttentionBridge, MoEClassifier, coverage loss.  
- **Современные подходы:** трансформеры и мультимодальность.  
- **Инфраструктура:** всё упаковано в микросервис на FastAPI и Docker.

---

## Ресурсы

- **Этап 1 (SwinUNETR):** ~10 дней на NVIDIA A100 (80 GB).  
- **Этап 2 (эмбеддинги):** ~1 день на A100.  
- **Этап 3 (голова):** ~3 дня на A100.  

**Инференс:** требует минимум ~60 GB GPU VRAM для прогонки целого 3D-объёма без кропа.  

---

## Запуск инференса

1. Установить зависимости:
   ```bash
   pip install -r requirements.txt
   ```
2. Запустить `inference.ipynb` — загрузка весов, инференс, сохранение результатов в DICOM.  

---

## Запуск микросервиса

```bash
uvicorn microservice:app --host 0.0.0.0 --port 8000
```

- Эндпоинт `/predict` принимает `.zip` с DICOM.  
- Возвращает `.zip` с сегментациями в DICOM.  

Пример:
```bash
curl -X POST "http://localhost:8000/predict" \
  -F "file=@dicoms.zip" \
  -o result.zip
```

---

## Запуск в Docker

```bash
docker build -t dicom-service .
docker run -p 8000:8000 dicom-service
```

---

## Итог

Даже в текущем состоянии проект:  
- обучен на мощных GPU,  
- использует грамотное извлечение эмбеддингов из бэкбона,  
- мультизадачен (сегментация + классификация + генерация),  
- готов к использованию как сервис,  
- имеет потенциал для визуализации внимания модели через аттеншен-мапы.  

Главный ограничитель — объём данных. На полном **CT-RATE** и с 3D-ViT можно кратно увеличить качество.
